# GPT2 from scratch

#### How to create GPT-2, a powerful language model developed by OpenAI from scratch that can generate human-like text by predicting the next word in a sequence.

[Part-1 >>](https://pub.towardsai.net/heres-how-you-can-build-and-train-gpt-2-from-scratch-using-pytorch-0253d01d2b63)

[Part-2 >>](https://pub.towardsai.net/heres-how-you-can-build-and-train-gpt-2-from-scratch-using-pytorch-part-2-9b41d15baf62)

part_1.py : Basic model NN learning
part_2.py : Positional Encoding (PE) + NN
part_3.py : (Masked) Self-Attention + Normalization
part_4.py : (Masked) Multi-head Attention
part_5.py : GPT Decoder Blocks
part_6.py : Improving Tokenizer
part_7.py : Final GPT-2 Training
